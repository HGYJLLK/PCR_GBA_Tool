"""
Live character detection  —  3-thread pipeline

Architecture:
    CaptureThread   captures frames as fast as NemuIpc allows (~10 ms/frame)
                    and writes the latest frame into a shared slot.

    DetectionThread reads the latest frame, runs grayscale template matching,
                    and writes results into another shared slot.
                    Runs independently — never blocks the display.

    Main thread     reads the latest raw frame + latest detections and renders
                    at display speed (~30 fps).  The display is always live even
                    when detection is slower.

Result: smooth live video with detection boxes overlaid asynchronously.

Template sources (--icons):
    assets   — use hand-annotated templates from module/character/assets.py (default)
    icons    — use pre-cropped icons from assets/icons/unit_cropped/
               (generate first with: python dev_tools/crop_icons.py)
"""

import argparse
import json
import os
import sys
import threading
import time
from concurrent.futures import ThreadPoolExecutor, as_completed

sys.path.insert(0, "./")

import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont

import module.character.assets as char_assets
from module.base.template import Template
from module.config.config import PriconneConfig
from module.device.device import Device
from module.logger import logger

# ── config ────────────────────────────────────────────────────────────────────
SIMILARITY_THRESHOLD  = 0.85
ICON_THRESHOLD        = 0.85   # threshold used when matching downloaded icons
SIDEBAR_W             = 220
WIN_TITLE             = "PCR Live Detection  (q=quit)"
MASK_PATH             = "./assets/mask/MASK_CHARACTER_LIST.png"
ICONS_DIR_CROPPED     = "./assets/icons/unit_cropped"
NAMES_FILE            = "./assets/icons/unit_names.json"


# ── shared slot (lock-free single-value exchange) ─────────────────────────────
class Slot:
    """Thread-safe single-value slot: writer always overwrites, reader gets latest."""
    def __init__(self):
        self._value = None
        self._lock  = threading.Lock()

    def put(self, value):
        with self._lock:
            self._value = value

    def get(self):
        with self._lock:
            return self._value


# ── mask ROI ──────────────────────────────────────────────────────────────────
def get_mask_roi(path):
    m = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
    if m is None:
        return None
    rows = np.where(m.max(axis=1) > 0)[0]
    cols = np.where(m.max(axis=0) > 0)[0]
    if rows.size == 0 or cols.size == 0:
        return None
    return int(rows[0]), int(rows[-1]) + 1, int(cols[0]), int(cols[-1]) + 1


# ── templates ─────────────────────────────────────────────────────────────────
def load_templates_gray():
    """Load hand-annotated templates from module/character/assets.py."""
    entries = []
    for attr in dir(char_assets):
        if not attr.startswith("TEMPLATE_"):
            continue
        obj = getattr(char_assets, attr)
        if not isinstance(obj, Template):
            continue
        name = attr[len("TEMPLATE_"):]
        try:
            gray = cv2.cvtColor(obj.image, cv2.COLOR_RGB2GRAY)
            entries.append((name, gray))
        except Exception as e:
            logger.warning(f"Skip {name}: {e}")
    return entries


def load_templates_icons(icons_dir=ICONS_DIR_CROPPED, names_file=NAMES_FILE,
                         size=50):
    """Load pre-cropped unit icons (generated by dev_tools/crop_icons.py).

    Loads ★1 (11), ★3 (31) and ★6 (61) variants to cover characters at
    any star level, including those not yet raised to ★3.
    """
    if not os.path.isdir(icons_dir):
        logger.error(f"Icons dir not found: {icons_dir}  "
                     f"— run: python dev_tools/crop_icons.py")
        return []

    with open(names_file, encoding="utf-8") as f:
        names = json.load(f)

    entries = []
    files = sorted(f for f in os.listdir(icons_dir) if f.endswith(".png"))
    for fn in files:
        uid = fn.replace(".png", "")
        if uid not in names:
            continue
        if not (uid.endswith("11") or uid.endswith("31") or uid.endswith("61")):
            continue
        img = cv2.imread(os.path.join(icons_dir, fn))
        if img is None:
            continue
        img = cv2.resize(img, (size, size), interpolation=cv2.INTER_AREA)
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        entries.append((names[uid], gray))
    return entries


# ── detection ─────────────────────────────────────────────────────────────────
def _match_one(gray_roi, x0, y0, name, tmpl, threshold):
    """Match a single template. Runs in a thread pool — cv2 releases the GIL."""
    th, tw = tmpl.shape[:2]
    if gray_roi.shape[0] < th or gray_roi.shape[1] < tw:
        return None
    res = cv2.matchTemplate(gray_roi, tmpl, cv2.TM_CCOEFF_NORMED)
    _, sim, _, (mx, my) = cv2.minMaxLoc(res)
    if sim >= threshold:
        return (name, (x0 + mx, y0 + my, x0 + mx + tw, y0 + my + th), sim)
    return None


def detect(gray_roi, roi_offset, templates_gray, pool, threshold):
    """Match all templates in parallel using the shared thread pool."""
    x0, y0 = roi_offset
    futures = {
        pool.submit(_match_one, gray_roi, x0, y0, name, tmpl, threshold): name
        for name, tmpl in templates_gray
    }
    hits = []
    for f in as_completed(futures):
        result = f.result()
        if result is not None:
            hits.append(result)
    hits.sort(key=lambda x: -x[2])
    return hits


# ── font & text ───────────────────────────────────────────────────────────────
def _load_font(size=14):
    for path in ["C:/Windows/Fonts/simhei.ttf",
                 "C:/Windows/Fonts/msyh.ttc",
                 "C:/Windows/Fonts/simsun.ttc"]:
        if os.path.exists(path):
            try:
                return ImageFont.truetype(path, size)
            except Exception:
                pass
    return ImageFont.load_default()

_FONT = _load_font()
_DUMMY_DRAW = ImageDraw.Draw(Image.new("RGB", (1, 1)))


def _put_text(frame_bgr, text, x, y):
    bb = _DUMMY_DRAW.textbbox((0, 0), text, font=_FONT)
    tw, th = bb[2] - bb[0], bb[3] - bb[1]
    patch = Image.new("RGB", (tw + 4, th + 4), (0, 0, 0))
    ImageDraw.Draw(patch).text((2, 2), text, font=_FONT, fill=(0, 255, 0))
    patch_bgr = cv2.cvtColor(np.array(patch), cv2.COLOR_RGB2BGR)
    fh, fw = frame_bgr.shape[:2]
    x1, y1 = max(0, x), max(0, y)
    x2, y2 = min(fw, x1 + patch_bgr.shape[1]), min(fh, y1 + patch_bgr.shape[0])
    frame_bgr[y1:y2, x1:x2] = patch_bgr[:y2 - y1, :x2 - x1]
    return th


# ── drawing ───────────────────────────────────────────────────────────────────
def draw_boxes(frame_bgr, detections):
    for name, (x1, y1, x2, y2), sim in detections:
        cv2.rectangle(frame_bgr, (x1, y1), (x2, y2), (0, 220, 0), 2)
        label = f"{name} {sim:.2f}"
        bb = _DUMMY_DRAW.textbbox((0, 0), label, font=_FONT)
        th = bb[3] - bb[1]
        ty = y1 - th - 4 if y1 - th - 4 >= 0 else y2 + 2
        _put_text(frame_bgr, label, x1, ty)


def draw_sidebar(frame_bgr, detections, total, det_ms, fps):
    h = frame_bgr.shape[0]
    bar = np.full((h, SIDEBAR_W, 3), 30, dtype=np.uint8)

    def put(text, y, color=(180, 180, 180), scale=0.42):
        cv2.putText(bar, text, (8, y), cv2.FONT_HERSHEY_SIMPLEX,
                    scale, color, 1, cv2.LINE_AA)

    put(f"Templates : {total}", 20)
    put(f"Detected  : {len(detections)}", 44,
        (0, 220, 80) if detections else (80, 80, 80), scale=0.48)
    put(f"Detect ms : {det_ms:.0f}", 64, (120, 120, 120))
    put(f"Display   : {fps:.0f} fps", 82, (120, 120, 120))
    cv2.line(bar, (4, 94), (SIDEBAR_W - 4, 94), (60, 60, 60), 1)

    y = 110
    for name, _, sim in detections:
        _put_text(bar, f"{name}  {sim:.2f}", 8, y)
        y += 18
        if y > h - 24:
            put("...", y, (100, 100, 100))
            break

    put("q = quit", h - 10, (80, 80, 80))
    return np.hstack([frame_bgr, bar])


# ── Thread 1: capture ─────────────────────────────────────────────────────────
class CaptureThread(threading.Thread):
    """Grabs frames as fast as possible and exposes the latest via a Slot."""

    def __init__(self, device):
        super().__init__(daemon=True)
        self.device     = device
        self.frame_slot = Slot()   # latest RGB frame
        self._stop      = threading.Event()

    def stop(self):
        self._stop.set()

    def run(self):
        while not self._stop.is_set():
            self.device.screenshot()
            self.frame_slot.put(self.device.image.copy())


# ── Thread 2: detection ───────────────────────────────────────────────────────
class DetectionThread(threading.Thread):
    """
    Reads the latest frame from CaptureThread, runs template matching
    in a thread pool (parallel), and exposes (detections, elapsed_ms) via a Slot.
    """

    def __init__(self, frame_slot, templates_gray, roi, threshold):
        super().__init__(daemon=True)
        self.frame_slot     = frame_slot
        self.templates_gray = templates_gray
        self.roi            = roi
        self.threshold      = threshold
        self.result_slot    = Slot()   # (detections, elapsed_ms)
        self._stop          = threading.Event()
        self._last_frame_id = None
        # One worker per template up to CPU count — matchTemplate releases the GIL
        n_workers = min(os.cpu_count() or 4, len(templates_gray))
        self._pool = ThreadPoolExecutor(max_workers=n_workers)
        logger.info(f"Detection pool: {n_workers} workers for {len(templates_gray)} templates")

    def stop(self):
        self._stop.set()
        self._pool.shutdown(wait=False)

    def run(self):
        while not self._stop.is_set():
            frame_rgb = self.frame_slot.get()

            if frame_rgb is None or id(frame_rgb) == self._last_frame_id:
                time.sleep(0.005)
                continue
            self._last_frame_id = id(frame_rgb)

            t0 = time.perf_counter()

            if self.roi:
                ry1, ry2, rx1, rx2 = self.roi
                crop   = frame_rgb[ry1:ry2, rx1:rx2]
                offset = (rx1, ry1)
            else:
                crop   = frame_rgb
                offset = (0, 0)

            gray       = cv2.cvtColor(crop, cv2.COLOR_RGB2GRAY)
            detections = detect(gray, offset, self.templates_gray, self._pool, self.threshold)
            elapsed_ms = (time.perf_counter() - t0) * 1000

            self.result_slot.put((detections, elapsed_ms))


# ── Main thread: display ──────────────────────────────────────────────────────
def run_live(device, use_icons=False):
    if use_icons:
        templates_gray = load_templates_icons()
        threshold = ICON_THRESHOLD
        src_label = f"icons (unit_cropped, thresh={threshold})"
    else:
        templates_gray = load_templates_gray()
        threshold = SIMILARITY_THRESHOLD
        src_label = f"assets (thresh={threshold})"

    if not templates_gray:
        logger.error("No templates loaded — aborting.")
        return

    logger.info(f"Loaded {len(templates_gray)} templates from {src_label}")

    roi = get_mask_roi(MASK_PATH)
    if roi:
        ry1, ry2, rx1, rx2 = roi
        logger.info(f"Mask ROI: x={rx1}-{rx2}, y={ry1}-{ry2} "
                    f"({rx2-rx1}x{ry2-ry1} px)")
    else:
        logger.warning("Mask not found, using full frame")

    capture   = CaptureThread(device)
    detection = DetectionThread(capture.frame_slot, templates_gray, roi, threshold)

    capture.start()
    detection.start()

    cv2.namedWindow(WIN_TITLE, cv2.WINDOW_AUTOSIZE)
    logger.info("Display started. Press q to quit.")

    detections = []
    det_ms     = 0.0
    fps_counter = 0
    fps_t0      = time.perf_counter()
    fps         = 0.0

    while True:
        frame_rgb = capture.frame_slot.get()
        if frame_rgb is None:
            if cv2.waitKey(10) & 0xFF == ord('q'):
                break
            continue

        result = detection.result_slot.get()
        if result is not None:
            detections, det_ms = result

        # render: BGR copy of the latest frame + last known boxes
        frame = cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2BGR)
        draw_boxes(frame, detections)
        display = draw_sidebar(frame, detections, len(templates_gray), det_ms, fps)
        cv2.imshow(WIN_TITLE, display)

        # fps
        fps_counter += 1
        elapsed = time.perf_counter() - fps_t0
        if elapsed >= 1.0:
            fps     = fps_counter / elapsed
            fps_counter = 0
            fps_t0  = time.perf_counter()
            if detections:
                names = ", ".join(n for n, _, _ in detections)
                logger.info(f"[det {det_ms:.0f}ms | {fps:.0f}fps] {len(detections)}: {names}")
            else:
                logger.info(f"[det {det_ms:.0f}ms | {fps:.0f}fps] no match")

        key = cv2.waitKey(1) & 0xFF
        if key == ord('q') or cv2.getWindowProperty(WIN_TITLE, cv2.WND_PROP_VISIBLE) < 1:
            break

    capture.stop()
    detection.stop()
    cv2.destroyAllWindows()
    logger.info("Stopped.")


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--icons", action="store_true",
                        help="Use pre-cropped icons from assets/icons/unit_cropped/ "
                             "instead of hand-annotated templates (thresh=0.70)")
    args = parser.parse_args()

    config = PriconneConfig("maple", "Pcr")
    device = Device(config)
    device.disable_stuck_detection()

    try:
        device._nemu_ipc_instance
        device.screenshot_method_override = "NemuIpc"
        logger.info("Using NemuIpc screenshot (~10-20 ms/frame)")
    except Exception as e:
        logger.warning(f"NemuIpc unavailable ({e}), using configured method")

    run_live(device, use_icons=args.icons)


if __name__ == "__main__":
    main()
